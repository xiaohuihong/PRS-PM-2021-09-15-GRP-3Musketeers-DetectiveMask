{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRNVzhoo1clG"
   },
   "source": [
    "## **1. Mount google drive**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5W39GXyk1hME",
    "outputId": "96356ba2-b7b3-445d-a7c7-70edea69fb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOQ-2xS_MYHi"
   },
   "source": [
    "## **2. Import the necessary libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoi4gWDELtek",
    "outputId": "353fe782-c5b0-47b9-83bb-428d410c6484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  2.5.0\n",
      "numpy:       1.19.5\n",
      "matplotlib:  3.2.2\n",
      "sklearn:     0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0amhwjZ4M2m-"
   },
   "source": [
    "## **3.Create a function to plot image without axis**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFxsBB1mNXl2",
    "outputId": "616d6736-988e-49e7-977b-87534a13be98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function implt at 0x7f689bb75f80>\n"
     ]
    }
   ],
   "source": [
    "def implt(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(implt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3N41iixORPz"
   },
   "source": [
    "## **4. Set matplotlib to have seaborn plot style**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyO5OsUrOYNQ",
    "outputId": "d5daeaf6-c3ac-41f9-bebc-cf6b8f98f604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib setup completes.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w2jAiKZOmgP"
   },
   "source": [
    "## **5. Prepare Cifar10 data for training and testing**\n",
    "---\n",
    "* Step 1: Load the cifar10 \n",
    "* Step 2: Check the shape and type of the data\n",
    "* Step 3: Convert the data into float32 and rescale the values from the range of 0\\~255 into 0\\~1\n",
    "* Step 4: Retrieve the row size and the column size of each image\n",
    "* Step 5: Perform one-hot enconding on the labels\n",
    "* Step 6: Retrieve the number of classes in this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3Ad2V0pO1TX",
    "outputId": "a23bb932-7cc8-444f-fcfd-387dd0b93aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "The shape of trDat is (50000, 32, 32, 3) and the type of trDat is uint8\n",
      "The shape of tsDat is (10000, 32, 32, 3) and the type of tsDat is uint8\n",
      "\n",
      "The shape of trLbl is (50000, 1) and the type of trLbl is uint8\n",
      "The shape of tsLbl is (10000, 1) and the type of tsLbl is uint8\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "data            = cifar10.load_data()\n",
    "(trDat, trLbl)  = data[0]\n",
    "(tsDat, tsLbl)  = data[1]\n",
    "\n",
    "                                                                                # Step 2\n",
    "print(\"The shape of trDat is\", trDat.shape, \"and the type of trDat is\", trDat.dtype)\n",
    "print(\"The shape of tsDat is\", tsDat.shape, \"and the type of tsDat is\", tsDat.dtype)\n",
    "print(\"\")\n",
    "print(\"The shape of trLbl is\", trLbl.shape, \"and the type of trLbl is\", trLbl.dtype)\n",
    "print(\"The shape of tsLbl is\", tsLbl.shape, \"and the type of tsLbl is\", tsLbl.dtype)\n",
    "\n",
    "                                                                                # Step 3\n",
    "trDat           = trDat.astype('float32')/255\n",
    "tsDat           = tsDat.astype('float32')/255\n",
    "\n",
    "                                                                                # Step 4\n",
    "imgrows         = trDat.shape[1]\n",
    "imgclms         = trDat.shape[2]\n",
    "channel         = trDat.shape[3]\n",
    "\n",
    "                                                                                # Step 5\n",
    "trLbl           = to_categorical(trLbl)\n",
    "tsLbl           = to_categorical(tsLbl)\n",
    "                               \n",
    "num_classes     = tsLbl.shape[1]                                                # Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoP3WcoJW-jZ"
   },
   "source": [
    "## **6. Define the resnet model (to be completed)**\n",
    "___\n",
    "* Step 1: Setup the optimizer to be used for training\n",
    "* Step 2: Set a name for the coming model (required for saving)\n",
    "* Step 3: Function to create layers for the resnet\n",
    "* Step 4: Function to create residual blocks\n",
    "* Step 5: Define the resnet model (to be completed)\n",
    "* Step 6: Create models for training and testing\n",
    "* Step 7: Display the summary of the model of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HMOes0kXCPd",
    "outputId": "4a471641-3bcd-4620-bca9-1f3b54a6516c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_conv (Conv2D)              (None, 32, 32, 16)   448         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_bn (BatchNormalization)    (None, 32, 32, 16)   64          Inpt_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Inpt_relu (Activation)          (None, 32, 32, 16)   0           Inpt_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Inpt_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_add (Add)             (None, 32, 32, 16)   0           Inpt_relu[0][0]                  \n",
      "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk1_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_add (Add)             (None, 32, 32, 16)   0           Stg1_Blk1_relu[0][0]             \n",
      "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk2_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_add (Add)             (None, 32, 32, 16)   0           Stg1_Blk2_relu[0][0]             \n",
      "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg1_Blk3_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_conv (Conv2D)    (None, 16, 16, 32)   4640        Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_lin_conv (Conv2D)     (None, 16, 16, 32)   544         Stg1_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk1_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk1_relu[0][0]             \n",
      "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk2_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk2_relu[0][0]             \n",
      "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg2_Blk3_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_conv (Conv2D)    (None, 8, 8, 64)     18496       Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk1_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_Blk1_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk1_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_lin_conv (Conv2D)     (None, 8, 8, 64)     2112        Stg2_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk1_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk1_lin_conv[0][0]         \n",
      "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk1_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk1_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk2_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_Blk2_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk2_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk2_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk1_relu[0][0]             \n",
      "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk2_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk2_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk3_Res1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_Blk3_Res1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk3_Res1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk3_Res2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk2_relu[0][0]             \n",
      "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Stg3_Blk3_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk3_add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "AvgPool (AveragePooling2D)      (None, 1, 1, 64)     0           Stg3_Blk3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           AvgPool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optmz       = optimizers.Adam(lr=0.001)                                         # Step 1\n",
    "modelname   = 'cifar10ResV1Cfg5'                                                # Step 2\n",
    "\n",
    "                                                                                # Step 3\n",
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSz=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "\n",
    "    convLyr     = Conv2D(numFilters,\n",
    "                         kernel_size=kernelSz,\n",
    "                         strides=strides,\n",
    "                         padding='same',\n",
    "                         kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=l2(1e-4),\n",
    "                         name=lyrName+'_conv' if lyrName else None)\n",
    "    x           = inputs\n",
    "    \n",
    "    if convFirst:\n",
    "        x       = convLyr(x)\n",
    "        \n",
    "        if batchNorm:\n",
    "            x   = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
    "            \n",
    "        if activation is not None:\n",
    "            x   = Activation(activation,\n",
    "                             name=lyrName+'_'+activation if lyrName else None)(x)\n",
    "    else:\n",
    "        if batchNorm:\n",
    "            x   = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
    "            \n",
    "        if activation is not None:\n",
    "            x   = Activation(activation,\n",
    "                             name=lyrName+'_'+activation if lyrName else None)(x)\n",
    "            \n",
    "        x       = convLyr(x)\n",
    "    return x\n",
    "\n",
    "                                                                                # Step 4\n",
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=3,\n",
    "             downsampleOnFirst=True,\n",
    "             names=None):\n",
    "    \n",
    "    x       = inputs\n",
    "    \n",
    "    for run in range(0,numBlocks):\n",
    "        strides = 1\n",
    "        blkStr  = str(run+1)\n",
    "        \n",
    "        if downsampleOnFirst and run == 0:\n",
    "            strides     = 2\n",
    "            \n",
    "        y       = resLyr(inputs=x,\n",
    "                         numFilters=numFilters,\n",
    "                         strides=strides,\n",
    "                         lyrName=names+'_Blk'+blkStr+'_Res1' if names else None)\n",
    "        y       = resLyr(inputs=y,\n",
    "                         numFilters=numFilters,\n",
    "                         activation=None,\n",
    "                         lyrName=names+'_Blk'+blkStr+'_Res2' if names else None)\n",
    "        \n",
    "        if downsampleOnFirst and run == 0:\n",
    "            x   = resLyr(inputs=x,\n",
    "                         numFilters=numFilters,\n",
    "                         kernelSz=1,\n",
    "                         strides=strides,\n",
    "                         activation=None,\n",
    "                         batchNorm=False,\n",
    "                         lyrName=names+'_Blk'+blkStr+'_lin' if names else None)\n",
    "\n",
    "        x       = add([x,y],\n",
    "                      name=names+'_Blk'+blkStr+'_add' if names else None)\n",
    "        x       = Activation('relu',\n",
    "                             name=names+'_Blk'+blkStr+'_relu' if names else None)(x)\n",
    "        \n",
    "    return x\n",
    "    \n",
    "                                                                                # Step 5\n",
    "def createResNetV1(inputShape=(32,32,3),\n",
    "                   numClasses=10):\n",
    "    inputs = Input(shape=inputShape)\n",
    "    v = resLyr(inputs, lyrName='Inpt')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=16,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=False,\n",
    "                 names='Stg1')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=32,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=True,\n",
    "                 names='Stg2')\n",
    "    v = resBlkV1(inputs=v,\n",
    "                 numFilters=64,\n",
    "                 numBlocks=3,\n",
    "                 downsampleOnFirst=True,\n",
    "                 names='Stg3')\n",
    "    v = AveragePooling2D(pool_size=8, name='AvgPool')(v)\n",
    "    v = Flatten()(v)\n",
    "    outputs = Dense(numClasses,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(v)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optmz,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "                                                                                # Step 6\n",
    "model       = createResNetV1()  # This is meant for training\n",
    "modelGo     = createResNetV1()  # This is used for final testing\n",
    "\n",
    "model.summary()                                                                 # Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlquJEaFZxV9"
   },
   "source": [
    "## **7. Create the callbacks to be applied during training**\n",
    "---\n",
    "* Step 1: Create a callback to save the model from an epoch when validation accuracy is the highest\n",
    "* Step 2: Create a callback to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
    "* Step 3: Put the two callback objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-a1LSCbahKy",
    "outputId": "0034a510-dd21-444d-8c7e-012e30d6b9c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks created:\n",
      "<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f6839fc5ad0>\n",
      "<tensorflow.python.keras.callbacks.CSVLogger object at 0x7f6839fc5990>\n",
      "<tensorflow.python.keras.callbacks.LearningRateScheduler object at 0x7f6839fc5850>\n",
      "\n",
      "Path to model: /content/gdrive/My Drive/iss/prumls/colab/cifar10ResV1Cfg5.hdf5\n",
      "Path to log:   /content/gdrive/My Drive/iss/prumls/colab/cifar10ResV1Cfg5.csv\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "def lrSchedule(epoch):\n",
    "    lr  = 1e-3\n",
    "    \n",
    "    if epoch > 160:\n",
    "        lr  *= 0.5e-3        \n",
    "    elif epoch > 140:\n",
    "        lr  *= 1e-3       \n",
    "    elif epoch > 120:\n",
    "        lr  *= 1e-2     \n",
    "    elif epoch > 80:\n",
    "        lr  *= 1e-1\n",
    "        \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "LRScheduler     = LearningRateScheduler(lrSchedule)\n",
    "\n",
    "                                                                                # Step 2\n",
    "folderpath      = '/content/gdrive/My Drive/iss/prumls/colab/'\n",
    "filepath        = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')                       # Step 2\n",
    "callbacks_list  = [checkpoint,csv_logger,LRScheduler]                           # Step 3\n",
    "\n",
    "print(\"Callbacks created:\")\n",
    "print(callbacks_list[0])\n",
    "print(callbacks_list[1])\n",
    "print(callbacks_list[2])\n",
    "print('')\n",
    "print(\"Path to model:\", filepath)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mKgjQsmfOBz"
   },
   "source": [
    "## **8. Train the deep learning model with image augmentation (to be completed)**\n",
    "___\n",
    "* Step 1: Create the image data generator (for image augmentation)\n",
    "* Step 2: Train the model with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23lUNwpGfV0A",
    "outputId": "5f272da1-74eb-4e64-b1ba-ac9dc5d4495e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 65s 81ms/step - loss: 1.6892 - accuracy: 0.4433 - val_loss: 1.6686 - val_accuracy: 0.4690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 1.3347 - accuracy: 0.5742 - val_loss: 1.7081 - val_accuracy: 0.5089\n",
      "Epoch 3/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 1.1673 - accuracy: 0.6366 - val_loss: 1.3156 - val_accuracy: 0.5959\n",
      "Epoch 4/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 1.0586 - accuracy: 0.6755 - val_loss: 1.1000 - val_accuracy: 0.6607\n",
      "Epoch 5/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.9809 - accuracy: 0.7047 - val_loss: 1.2576 - val_accuracy: 0.6402\n",
      "Epoch 6/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.9130 - accuracy: 0.7308 - val_loss: 1.2140 - val_accuracy: 0.6673\n",
      "Epoch 7/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.8662 - accuracy: 0.7480 - val_loss: 0.9908 - val_accuracy: 0.7190\n",
      "Epoch 8/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 0.8232 - accuracy: 0.7616 - val_loss: 0.9305 - val_accuracy: 0.7360\n",
      "Epoch 9/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.7872 - accuracy: 0.7753 - val_loss: 1.1998 - val_accuracy: 0.6655\n",
      "Epoch 10/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.7606 - accuracy: 0.7840 - val_loss: 0.8314 - val_accuracy: 0.7649\n",
      "Epoch 11/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.7320 - accuracy: 0.7946 - val_loss: 0.8682 - val_accuracy: 0.7532\n",
      "Epoch 12/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.7189 - accuracy: 0.8008 - val_loss: 0.8989 - val_accuracy: 0.7512\n",
      "Epoch 13/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.6949 - accuracy: 0.8067 - val_loss: 0.9126 - val_accuracy: 0.7456\n",
      "Epoch 14/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.6784 - accuracy: 0.8130 - val_loss: 0.9762 - val_accuracy: 0.7366\n",
      "Epoch 15/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.6688 - accuracy: 0.8184 - val_loss: 0.8367 - val_accuracy: 0.7676\n",
      "Epoch 16/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.6517 - accuracy: 0.8244 - val_loss: 1.2076 - val_accuracy: 0.6900\n",
      "Epoch 17/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.6320 - accuracy: 0.8320 - val_loss: 0.7735 - val_accuracy: 0.7892\n",
      "Epoch 18/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.6221 - accuracy: 0.8344 - val_loss: 0.8689 - val_accuracy: 0.7678\n",
      "Epoch 19/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.6079 - accuracy: 0.8385 - val_loss: 0.9099 - val_accuracy: 0.7618\n",
      "Epoch 20/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.6003 - accuracy: 0.8421 - val_loss: 0.7920 - val_accuracy: 0.7948\n",
      "Epoch 21/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.5914 - accuracy: 0.8444 - val_loss: 0.7103 - val_accuracy: 0.8138\n",
      "Epoch 22/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.5853 - accuracy: 0.8462 - val_loss: 1.0930 - val_accuracy: 0.7344\n",
      "Epoch 23/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.5749 - accuracy: 0.8506 - val_loss: 0.7574 - val_accuracy: 0.8025\n",
      "Epoch 24/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.5672 - accuracy: 0.8546 - val_loss: 0.7541 - val_accuracy: 0.8060\n",
      "Epoch 25/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.5561 - accuracy: 0.8566 - val_loss: 0.7907 - val_accuracy: 0.7952\n",
      "Epoch 26/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.5562 - accuracy: 0.8565 - val_loss: 0.8993 - val_accuracy: 0.7619\n",
      "Epoch 27/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.5494 - accuracy: 0.8607 - val_loss: 0.8432 - val_accuracy: 0.7843\n",
      "Epoch 28/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.5407 - accuracy: 0.8648 - val_loss: 0.9504 - val_accuracy: 0.7568\n",
      "Epoch 29/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.5371 - accuracy: 0.8653 - val_loss: 0.6846 - val_accuracy: 0.8204\n",
      "Epoch 30/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.5328 - accuracy: 0.8662 - val_loss: 0.7644 - val_accuracy: 0.8059\n",
      "Epoch 31/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.5199 - accuracy: 0.8697 - val_loss: 0.7918 - val_accuracy: 0.7974\n",
      "Epoch 32/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.5198 - accuracy: 0.8714 - val_loss: 0.8318 - val_accuracy: 0.7761\n",
      "Epoch 33/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.5165 - accuracy: 0.8726 - val_loss: 0.9054 - val_accuracy: 0.7852\n",
      "Epoch 34/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.5160 - accuracy: 0.8731 - val_loss: 0.7519 - val_accuracy: 0.8087\n",
      "Epoch 35/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.5043 - accuracy: 0.8747 - val_loss: 0.9158 - val_accuracy: 0.7800\n",
      "Epoch 36/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.5041 - accuracy: 0.8769 - val_loss: 0.7054 - val_accuracy: 0.8211\n",
      "Epoch 37/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.4945 - accuracy: 0.8801 - val_loss: 0.8128 - val_accuracy: 0.8019\n",
      "Epoch 38/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.4942 - accuracy: 0.8793 - val_loss: 0.6505 - val_accuracy: 0.8344\n",
      "Epoch 39/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.4939 - accuracy: 0.8802 - val_loss: 0.7326 - val_accuracy: 0.8121\n",
      "Epoch 40/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.4935 - accuracy: 0.8807 - val_loss: 0.6850 - val_accuracy: 0.8239\n",
      "Epoch 41/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4864 - accuracy: 0.8831 - val_loss: 0.8453 - val_accuracy: 0.7890\n",
      "Epoch 42/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.4834 - accuracy: 0.8848 - val_loss: 0.7995 - val_accuracy: 0.8036\n",
      "Epoch 43/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4810 - accuracy: 0.8848 - val_loss: 0.6282 - val_accuracy: 0.8389\n",
      "Epoch 44/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4820 - accuracy: 0.8847 - val_loss: 0.6956 - val_accuracy: 0.8198\n",
      "Epoch 45/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.4771 - accuracy: 0.8857 - val_loss: 0.6833 - val_accuracy: 0.8315\n",
      "Epoch 46/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 33s 86ms/step - loss: 0.4682 - accuracy: 0.8898 - val_loss: 0.7513 - val_accuracy: 0.8173\n",
      "Epoch 47/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4744 - accuracy: 0.8871 - val_loss: 0.6033 - val_accuracy: 0.8508\n",
      "Epoch 48/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.4623 - accuracy: 0.8899 - val_loss: 0.6528 - val_accuracy: 0.8369\n",
      "Epoch 49/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.4688 - accuracy: 0.8889 - val_loss: 0.7796 - val_accuracy: 0.8007\n",
      "Epoch 50/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4672 - accuracy: 0.8912 - val_loss: 1.1923 - val_accuracy: 0.7484\n",
      "Epoch 51/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.4635 - accuracy: 0.8923 - val_loss: 0.8219 - val_accuracy: 0.8108\n",
      "Epoch 52/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4650 - accuracy: 0.8912 - val_loss: 0.6689 - val_accuracy: 0.8280\n",
      "Epoch 53/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.4598 - accuracy: 0.8924 - val_loss: 0.6567 - val_accuracy: 0.8425\n",
      "Epoch 54/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.4559 - accuracy: 0.8951 - val_loss: 0.7172 - val_accuracy: 0.8210\n",
      "Epoch 55/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4513 - accuracy: 0.8960 - val_loss: 1.0511 - val_accuracy: 0.7658\n",
      "Epoch 56/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4502 - accuracy: 0.8973 - val_loss: 0.7425 - val_accuracy: 0.8100\n",
      "Epoch 57/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4466 - accuracy: 0.8971 - val_loss: 0.7538 - val_accuracy: 0.8201\n",
      "Epoch 58/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4472 - accuracy: 0.8970 - val_loss: 0.6369 - val_accuracy: 0.8388\n",
      "Epoch 59/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4436 - accuracy: 0.8985 - val_loss: 0.6017 - val_accuracy: 0.8519\n",
      "Epoch 60/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4437 - accuracy: 0.8978 - val_loss: 0.7058 - val_accuracy: 0.8226\n",
      "Epoch 61/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.4488 - accuracy: 0.8984 - val_loss: 1.0019 - val_accuracy: 0.7810\n",
      "Epoch 62/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4391 - accuracy: 0.9006 - val_loss: 0.7504 - val_accuracy: 0.8173\n",
      "Epoch 63/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.4487 - accuracy: 0.8975 - val_loss: 0.6550 - val_accuracy: 0.8467\n",
      "Epoch 64/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.4409 - accuracy: 0.9001 - val_loss: 0.6552 - val_accuracy: 0.8486\n",
      "Epoch 65/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.4334 - accuracy: 0.9021 - val_loss: 0.6196 - val_accuracy: 0.8420\n",
      "Epoch 66/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.4360 - accuracy: 0.9028 - val_loss: 0.5939 - val_accuracy: 0.8601\n",
      "Epoch 67/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.4344 - accuracy: 0.9029 - val_loss: 0.8390 - val_accuracy: 0.8074\n",
      "Epoch 68/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.4343 - accuracy: 0.9025 - val_loss: 0.7128 - val_accuracy: 0.8332\n",
      "Epoch 69/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.4348 - accuracy: 0.9028 - val_loss: 0.5882 - val_accuracy: 0.8600\n",
      "Epoch 70/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.4346 - accuracy: 0.9028 - val_loss: 0.5756 - val_accuracy: 0.8634\n",
      "Epoch 71/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.4271 - accuracy: 0.9050 - val_loss: 0.7504 - val_accuracy: 0.8312\n",
      "Epoch 72/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.4279 - accuracy: 0.9051 - val_loss: 0.6569 - val_accuracy: 0.8455\n",
      "Epoch 73/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4253 - accuracy: 0.9068 - val_loss: 0.6578 - val_accuracy: 0.8434\n",
      "Epoch 74/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4288 - accuracy: 0.9037 - val_loss: 0.7243 - val_accuracy: 0.8406\n",
      "Epoch 75/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.4272 - accuracy: 0.9052 - val_loss: 0.6292 - val_accuracy: 0.8418\n",
      "Epoch 76/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.4302 - accuracy: 0.9046 - val_loss: 0.6601 - val_accuracy: 0.8521\n",
      "Epoch 77/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.4202 - accuracy: 0.9077 - val_loss: 0.6762 - val_accuracy: 0.8413\n",
      "Epoch 78/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4255 - accuracy: 0.9069 - val_loss: 0.7319 - val_accuracy: 0.8291\n",
      "Epoch 79/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.4238 - accuracy: 0.9064 - val_loss: 0.6312 - val_accuracy: 0.8542\n",
      "Epoch 80/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.4161 - accuracy: 0.9088 - val_loss: 0.7582 - val_accuracy: 0.8157\n",
      "Epoch 81/200\n",
      "Learning rate:  0.001\n",
      "390/390 [==============================] - 31s 81ms/step - loss: 0.4214 - accuracy: 0.9072 - val_loss: 0.6869 - val_accuracy: 0.8357\n",
      "Epoch 82/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3610 - accuracy: 0.9294 - val_loss: 0.4747 - val_accuracy: 0.8933\n",
      "Epoch 83/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.3369 - accuracy: 0.9380 - val_loss: 0.4689 - val_accuracy: 0.8980\n",
      "Epoch 84/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3254 - accuracy: 0.9410 - val_loss: 0.4721 - val_accuracy: 0.8977\n",
      "Epoch 85/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.3179 - accuracy: 0.9427 - val_loss: 0.4750 - val_accuracy: 0.8961\n",
      "Epoch 86/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.3094 - accuracy: 0.9454 - val_loss: 0.4613 - val_accuracy: 0.8992\n",
      "Epoch 87/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3067 - accuracy: 0.9459 - val_loss: 0.4940 - val_accuracy: 0.8914\n",
      "Epoch 88/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.3015 - accuracy: 0.9481 - val_loss: 0.4713 - val_accuracy: 0.8984\n",
      "Epoch 89/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2970 - accuracy: 0.9486 - val_loss: 0.4540 - val_accuracy: 0.9030\n",
      "Epoch 90/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2957 - accuracy: 0.9495 - val_loss: 0.4667 - val_accuracy: 0.8983\n",
      "Epoch 91/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.2927 - accuracy: 0.9506 - val_loss: 0.4764 - val_accuracy: 0.8982\n",
      "Epoch 92/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2896 - accuracy: 0.9510 - val_loss: 0.4602 - val_accuracy: 0.9010\n",
      "Epoch 93/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.2855 - accuracy: 0.9523 - val_loss: 0.4691 - val_accuracy: 0.8996\n",
      "Epoch 94/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2826 - accuracy: 0.9513 - val_loss: 0.4658 - val_accuracy: 0.9006\n",
      "Epoch 95/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2804 - accuracy: 0.9532 - val_loss: 0.4758 - val_accuracy: 0.8990\n",
      "Epoch 96/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2806 - accuracy: 0.9533 - val_loss: 0.4638 - val_accuracy: 0.9003\n",
      "Epoch 97/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 33s 83ms/step - loss: 0.2772 - accuracy: 0.9529 - val_loss: 0.4787 - val_accuracy: 0.8953\n",
      "Epoch 98/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2715 - accuracy: 0.9544 - val_loss: 0.4741 - val_accuracy: 0.8987\n",
      "Epoch 99/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2711 - accuracy: 0.9546 - val_loss: 0.4647 - val_accuracy: 0.9007\n",
      "Epoch 100/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2671 - accuracy: 0.9569 - val_loss: 0.4532 - val_accuracy: 0.9020\n",
      "Epoch 101/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2646 - accuracy: 0.9572 - val_loss: 0.4694 - val_accuracy: 0.8982\n",
      "Epoch 102/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2680 - accuracy: 0.9553 - val_loss: 0.4604 - val_accuracy: 0.9023\n",
      "Epoch 103/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2626 - accuracy: 0.9576 - val_loss: 0.4525 - val_accuracy: 0.9025\n",
      "Epoch 104/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2605 - accuracy: 0.9563 - val_loss: 0.4589 - val_accuracy: 0.9006\n",
      "Epoch 105/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2579 - accuracy: 0.9567 - val_loss: 0.4535 - val_accuracy: 0.9029\n",
      "Epoch 106/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 33s 83ms/step - loss: 0.2583 - accuracy: 0.9565 - val_loss: 0.4627 - val_accuracy: 0.9021\n",
      "Epoch 107/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 33s 83ms/step - loss: 0.2535 - accuracy: 0.9587 - val_loss: 0.4603 - val_accuracy: 0.9024\n",
      "Epoch 108/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2516 - accuracy: 0.9601 - val_loss: 0.4598 - val_accuracy: 0.9031\n",
      "Epoch 109/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2534 - accuracy: 0.9586 - val_loss: 0.4770 - val_accuracy: 0.8962\n",
      "Epoch 110/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2510 - accuracy: 0.9587 - val_loss: 0.4569 - val_accuracy: 0.9021\n",
      "Epoch 111/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2488 - accuracy: 0.9596 - val_loss: 0.4583 - val_accuracy: 0.8990\n",
      "Epoch 112/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2476 - accuracy: 0.9584 - val_loss: 0.4947 - val_accuracy: 0.8928\n",
      "Epoch 113/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2471 - accuracy: 0.9610 - val_loss: 0.4438 - val_accuracy: 0.9041\n",
      "Epoch 114/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2450 - accuracy: 0.9605 - val_loss: 0.4645 - val_accuracy: 0.9016\n",
      "Epoch 115/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2445 - accuracy: 0.9600 - val_loss: 0.4832 - val_accuracy: 0.8959\n",
      "Epoch 116/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2442 - accuracy: 0.9599 - val_loss: 0.4619 - val_accuracy: 0.9021\n",
      "Epoch 117/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2407 - accuracy: 0.9612 - val_loss: 0.4928 - val_accuracy: 0.8948\n",
      "Epoch 118/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2377 - accuracy: 0.9614 - val_loss: 0.4733 - val_accuracy: 0.8980\n",
      "Epoch 119/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2374 - accuracy: 0.9619 - val_loss: 0.4865 - val_accuracy: 0.8999\n",
      "Epoch 120/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.2358 - accuracy: 0.9625 - val_loss: 0.4530 - val_accuracy: 0.9030\n",
      "Epoch 121/200\n",
      "Learning rate:  0.0001\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2349 - accuracy: 0.9622 - val_loss: 0.4587 - val_accuracy: 0.9012\n",
      "Epoch 122/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2279 - accuracy: 0.9652 - val_loss: 0.4571 - val_accuracy: 0.9029\n",
      "Epoch 123/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.2266 - accuracy: 0.9653 - val_loss: 0.4547 - val_accuracy: 0.9035\n",
      "Epoch 124/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2251 - accuracy: 0.9654 - val_loss: 0.4527 - val_accuracy: 0.9043\n",
      "Epoch 125/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2242 - accuracy: 0.9663 - val_loss: 0.4537 - val_accuracy: 0.9048\n",
      "Epoch 126/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2270 - accuracy: 0.9653 - val_loss: 0.4531 - val_accuracy: 0.9040\n",
      "Epoch 127/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2242 - accuracy: 0.9659 - val_loss: 0.4486 - val_accuracy: 0.9037\n",
      "Epoch 128/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2249 - accuracy: 0.9663 - val_loss: 0.4495 - val_accuracy: 0.9026\n",
      "Epoch 129/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2232 - accuracy: 0.9662 - val_loss: 0.4504 - val_accuracy: 0.9036\n",
      "Epoch 130/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2240 - accuracy: 0.9663 - val_loss: 0.4527 - val_accuracy: 0.9036\n",
      "Epoch 131/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2238 - accuracy: 0.9665 - val_loss: 0.4475 - val_accuracy: 0.9040\n",
      "Epoch 132/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2229 - accuracy: 0.9666 - val_loss: 0.4478 - val_accuracy: 0.9039\n",
      "Epoch 133/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2216 - accuracy: 0.9675 - val_loss: 0.4498 - val_accuracy: 0.9042\n",
      "Epoch 134/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2204 - accuracy: 0.9670 - val_loss: 0.4520 - val_accuracy: 0.9031\n",
      "Epoch 135/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2200 - accuracy: 0.9672 - val_loss: 0.4480 - val_accuracy: 0.9036\n",
      "Epoch 136/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2211 - accuracy: 0.9669 - val_loss: 0.4479 - val_accuracy: 0.9051\n",
      "Epoch 137/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2214 - accuracy: 0.9664 - val_loss: 0.4513 - val_accuracy: 0.9037\n",
      "Epoch 138/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 33s 84ms/step - loss: 0.2228 - accuracy: 0.9655 - val_loss: 0.4496 - val_accuracy: 0.9049\n",
      "Epoch 139/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.2195 - accuracy: 0.9679 - val_loss: 0.4493 - val_accuracy: 0.9047\n",
      "Epoch 140/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2206 - accuracy: 0.9677 - val_loss: 0.4524 - val_accuracy: 0.9041\n",
      "Epoch 141/200\n",
      "Learning rate:  1e-05\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.2186 - accuracy: 0.9682 - val_loss: 0.4532 - val_accuracy: 0.9045\n",
      "Epoch 142/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2168 - accuracy: 0.9688 - val_loss: 0.4504 - val_accuracy: 0.9045\n",
      "Epoch 143/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.2174 - accuracy: 0.9683 - val_loss: 0.4496 - val_accuracy: 0.9043\n",
      "Epoch 144/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2163 - accuracy: 0.9693 - val_loss: 0.4483 - val_accuracy: 0.9046\n",
      "Epoch 145/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2173 - accuracy: 0.9693 - val_loss: 0.4499 - val_accuracy: 0.9041\n",
      "Epoch 146/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2187 - accuracy: 0.9677 - val_loss: 0.4502 - val_accuracy: 0.9041\n",
      "Epoch 147/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2185 - accuracy: 0.9687 - val_loss: 0.4522 - val_accuracy: 0.9042\n",
      "Epoch 148/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2176 - accuracy: 0.9675 - val_loss: 0.4508 - val_accuracy: 0.9040\n",
      "Epoch 149/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.2177 - accuracy: 0.9677 - val_loss: 0.4500 - val_accuracy: 0.9038\n",
      "Epoch 150/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2202 - accuracy: 0.9670 - val_loss: 0.4511 - val_accuracy: 0.9040\n",
      "Epoch 151/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2192 - accuracy: 0.9677 - val_loss: 0.4509 - val_accuracy: 0.9041\n",
      "Epoch 152/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2194 - accuracy: 0.9676 - val_loss: 0.4501 - val_accuracy: 0.9043\n",
      "Epoch 153/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2171 - accuracy: 0.9684 - val_loss: 0.4477 - val_accuracy: 0.9045\n",
      "Epoch 154/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 83ms/step - loss: 0.2180 - accuracy: 0.9681 - val_loss: 0.4493 - val_accuracy: 0.9046\n",
      "Epoch 155/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2178 - accuracy: 0.9679 - val_loss: 0.4499 - val_accuracy: 0.9044\n",
      "Epoch 156/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 33s 83ms/step - loss: 0.2158 - accuracy: 0.9693 - val_loss: 0.4507 - val_accuracy: 0.9042\n",
      "Epoch 157/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2170 - accuracy: 0.9685 - val_loss: 0.4523 - val_accuracy: 0.9039\n",
      "Epoch 158/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2177 - accuracy: 0.9679 - val_loss: 0.4510 - val_accuracy: 0.9041\n",
      "Epoch 159/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2174 - accuracy: 0.9687 - val_loss: 0.4506 - val_accuracy: 0.9038\n",
      "Epoch 160/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2181 - accuracy: 0.9687 - val_loss: 0.4496 - val_accuracy: 0.9036\n",
      "Epoch 161/200\n",
      "Learning rate:  1e-06\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2165 - accuracy: 0.9683 - val_loss: 0.4494 - val_accuracy: 0.9045\n",
      "Epoch 162/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2188 - accuracy: 0.9670 - val_loss: 0.4506 - val_accuracy: 0.9040\n",
      "Epoch 163/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2158 - accuracy: 0.9689 - val_loss: 0.4506 - val_accuracy: 0.9039\n",
      "Epoch 164/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2166 - accuracy: 0.9678 - val_loss: 0.4508 - val_accuracy: 0.9039\n",
      "Epoch 165/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.2161 - accuracy: 0.9687 - val_loss: 0.4508 - val_accuracy: 0.9037\n",
      "Epoch 166/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2179 - accuracy: 0.9681 - val_loss: 0.4509 - val_accuracy: 0.9036\n",
      "Epoch 167/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.2155 - accuracy: 0.9686 - val_loss: 0.4499 - val_accuracy: 0.9042\n",
      "Epoch 168/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2164 - accuracy: 0.9678 - val_loss: 0.4480 - val_accuracy: 0.9046\n",
      "Epoch 169/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.2150 - accuracy: 0.9691 - val_loss: 0.4492 - val_accuracy: 0.9049\n",
      "Epoch 170/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2171 - accuracy: 0.9686 - val_loss: 0.4506 - val_accuracy: 0.9042\n",
      "Epoch 171/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2180 - accuracy: 0.9684 - val_loss: 0.4522 - val_accuracy: 0.9037\n",
      "Epoch 172/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.2188 - accuracy: 0.9679 - val_loss: 0.4513 - val_accuracy: 0.9038\n",
      "Epoch 173/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.2188 - accuracy: 0.9680 - val_loss: 0.4503 - val_accuracy: 0.9042\n",
      "Epoch 174/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2159 - accuracy: 0.9687 - val_loss: 0.4513 - val_accuracy: 0.9042\n",
      "Epoch 175/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2171 - accuracy: 0.9686 - val_loss: 0.4499 - val_accuracy: 0.9044\n",
      "Epoch 176/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.2186 - accuracy: 0.9674 - val_loss: 0.4515 - val_accuracy: 0.9044\n",
      "Epoch 177/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2183 - accuracy: 0.9670 - val_loss: 0.4502 - val_accuracy: 0.9047\n",
      "Epoch 178/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2173 - accuracy: 0.9679 - val_loss: 0.4514 - val_accuracy: 0.9041\n",
      "Epoch 179/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.2159 - accuracy: 0.9690 - val_loss: 0.4514 - val_accuracy: 0.9040\n",
      "Epoch 180/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2177 - accuracy: 0.9675 - val_loss: 0.4500 - val_accuracy: 0.9042\n",
      "Epoch 181/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2182 - accuracy: 0.9688 - val_loss: 0.4515 - val_accuracy: 0.9040\n",
      "Epoch 182/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.2157 - accuracy: 0.9685 - val_loss: 0.4500 - val_accuracy: 0.9044\n",
      "Epoch 183/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2184 - accuracy: 0.9674 - val_loss: 0.4498 - val_accuracy: 0.9043\n",
      "Epoch 184/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.2181 - accuracy: 0.9678 - val_loss: 0.4494 - val_accuracy: 0.9050\n",
      "Epoch 185/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.2203 - accuracy: 0.9675 - val_loss: 0.4495 - val_accuracy: 0.9046\n",
      "Epoch 186/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2182 - accuracy: 0.9686 - val_loss: 0.4501 - val_accuracy: 0.9042\n",
      "Epoch 187/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2172 - accuracy: 0.9685 - val_loss: 0.4506 - val_accuracy: 0.9042\n",
      "Epoch 188/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2150 - accuracy: 0.9688 - val_loss: 0.4516 - val_accuracy: 0.9040\n",
      "Epoch 189/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.2177 - accuracy: 0.9684 - val_loss: 0.4495 - val_accuracy: 0.9046\n",
      "Epoch 190/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2180 - accuracy: 0.9674 - val_loss: 0.4508 - val_accuracy: 0.9045\n",
      "Epoch 191/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2207 - accuracy: 0.9669 - val_loss: 0.4501 - val_accuracy: 0.9044\n",
      "Epoch 192/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2169 - accuracy: 0.9677 - val_loss: 0.4498 - val_accuracy: 0.9049\n",
      "Epoch 193/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 32s 82ms/step - loss: 0.2181 - accuracy: 0.9684 - val_loss: 0.4508 - val_accuracy: 0.9044\n",
      "Epoch 194/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.2170 - accuracy: 0.9693 - val_loss: 0.4512 - val_accuracy: 0.9042\n",
      "Epoch 195/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 32s 81ms/step - loss: 0.2167 - accuracy: 0.9696 - val_loss: 0.4513 - val_accuracy: 0.9045\n",
      "Epoch 196/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.2185 - accuracy: 0.9675 - val_loss: 0.4500 - val_accuracy: 0.9039\n",
      "Epoch 197/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 80ms/step - loss: 0.2179 - accuracy: 0.9681 - val_loss: 0.4523 - val_accuracy: 0.9036\n",
      "Epoch 198/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.2161 - accuracy: 0.9688 - val_loss: 0.4508 - val_accuracy: 0.9042\n",
      "Epoch 199/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 78ms/step - loss: 0.2174 - accuracy: 0.9681 - val_loss: 0.4502 - val_accuracy: 0.9041\n",
      "Epoch 200/200\n",
      "Learning rate:  5e-07\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.2124 - accuracy: 0.9700 - val_loss: 0.4509 - val_accuracy: 0.9039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6896b9eed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             rotation_range=20,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=False)\n",
    "\n",
    "                                                                              \n",
    "# Step 2\n",
    "model.fit(datagen.flow(trDat, trLbl, batch_size=128),\n",
    "          validation_data=(tsDat, tsLbl),\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          steps_per_epoch=len(trDat)/128,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TevfJTd-s0nk"
   },
   "source": [
    "## **9. Validate the deep learning model**\n",
    "---\n",
    "* Step 1: Load the trained weights and compile the model\n",
    "* Step 2: Make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sVtWmcVtiV5",
    "outputId": "7d916ffe-37fb-4c17-baf6-9fd3a4c9dc9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completes.\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "modelGo.load_weights(filepath)\n",
    "modelGo.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optmz, \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "predicts    = modelGo.predict(tsDat)                                            # Step 2\n",
    "print(\"Prediction completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aOCUljp5qq4"
   },
   "source": [
    "## **10. Report classification metrics**\n",
    "---\n",
    "* Step 1: Setup the label\n",
    "* Step 2: Convert label from one-hot to integer\n",
    "* Step 3: Calculate the accuracy score\n",
    "* Step 4: Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tI4hBmk5uRh",
    "outputId": "05de10ee-7fca-4e06-86f2-e89ddeee7b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy (on testing dataset): 90.51%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane     0.9122    0.9140    0.9131      1000\n",
      "  automobile     0.9326    0.9690    0.9505      1000\n",
      "        bird     0.8841    0.8850    0.8846      1000\n",
      "         cat     0.8271    0.7940    0.8102      1000\n",
      "        deer     0.9083    0.9010    0.9046      1000\n",
      "         dog     0.9083    0.8020    0.8518      1000\n",
      "        frog     0.8755    0.9630    0.9171      1000\n",
      "       horse     0.9449    0.9260    0.9354      1000\n",
      "        ship     0.9449    0.9440    0.9445      1000\n",
      "       truck     0.9128    0.9530    0.9325      1000\n",
      "\n",
      "    accuracy                         0.9051     10000\n",
      "   macro avg     0.9051    0.9051    0.9044     10000\n",
      "weighted avg     0.9051    0.9051    0.9044     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "labelname   = ['airplane',          # The label for reporting metrics\n",
    "               'automobile',\n",
    "               'bird',\n",
    "               'cat',\n",
    "               'deer',\n",
    "               'dog',\n",
    "               'frog',\n",
    "               'horse',\n",
    "               'ship',\n",
    "               'truck']\n",
    "                                                                                # Step 2\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(tsLbl,axis=1)\n",
    "\n",
    "testScores  = metrics.accuracy_score(testout,predout)                           # Step 3\n",
    "\n",
    "                                                                                # Step 4\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=labelname,\n",
    "                                    digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEK_4UXN6IVa"
   },
   "source": [
    "## **11. Print confusion matrix**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCBJCYp26L1t",
    "outputId": "50041b0a-6d5d-4630-ebfe-4ce0b5849159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[914   9  17   5   2   1   3   3  27  19]\n",
      " [  3 969   1   0   0   0   0   0   4  23]\n",
      " [ 23   3 885  21  15   8  34   3   3   5]\n",
      " [ 13  10  28 794  31  52  39  16   4  13]\n",
      " [  2   2  26  17 901   9  27  14   1   1]\n",
      " [  6   4  23  96  18 802  26  17   1   7]\n",
      " [  5   3   8   9   4   4 963   1   2   1]\n",
      " [  5   2  10  16  21   7   4 926   3   6]\n",
      " [ 25  10   3   0   0   0   2   0 944  16]\n",
      " [  6  27   0   2   0   0   2   0  10 953]]\n"
     ]
    }
   ],
   "source": [
    "confusion   = metrics.confusion_matrix(testout,predout)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QMIDPD46UGT"
   },
   "source": [
    "## **12. Plot curves on validation loss and accuracy**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "qr2ZbvUi6YHf",
    "outputId": "96a7f47c-cff7-41bd-dbef-65a3f2891650"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "records     = pd.read_csv(folderpath+modelname +'.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.50,1.00,1.50])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_accuracy'],label=\"validation\")\n",
    "plt.plot(records['accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWoTz-bLug3X"
   },
   "source": [
    "## **13. Save the model plot**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tz1YfuV1ujcE",
    "outputId": "b9cc0e74-bbcb-414f-e583-6db36b0938b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to plot: /content/gdrive/My Drive/iss/prumls/colab/cifar10ResV1Cfg5_plot.png\n"
     ]
    }
   ],
   "source": [
    "plotpath  = folderpath+modelname+'_plot.png'\n",
    "plot_model(model, \n",
    "           to_file=plotpath, \n",
    "           show_shapes=True, \n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')\n",
    "\n",
    "print(\"Path to plot:\", plotpath)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "prumls_wks4_2__S9476943D_HongXiaohui.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
