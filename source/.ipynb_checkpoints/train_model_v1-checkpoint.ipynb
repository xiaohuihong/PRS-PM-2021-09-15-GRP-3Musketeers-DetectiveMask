{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import the necessary libraries** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  2.3.0\n",
      "numpy:       1.18.5\n",
      "matplotlib:  3.4.2\n",
      "sklearn:     0.24.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.Create a function to plot image without axis** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function implt at 0x00000284FFCCD678>\n"
     ]
    }
   ],
   "source": [
    "def implt(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(implt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Set matplotlib to have seaborn plot style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib setup completes.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Prepare data for training and testing**\n",
    "---\n",
    "* Step 1: Load the images\n",
    "* Step 2: Check the shape and type of the data\n",
    "* Step 3: Convert the data into float32 and rescale the values from the range of 0\\~255 into 0\\~1\n",
    "* Step 4: Retrieve the row size and the column size of each image\n",
    "* Step 5: Perform one-hot enconding on the labels\n",
    "* Step 6: Retrieve the number of classes in this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONG0\\.conda\\envs\\detective_mask\\lib\\site-packages\\PIL\\Image.py:974: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trDat is (6042, 224, 224, 3) and the type of trDat is float32\n",
      "The shape of tsDat is (1511, 224, 224, 3) and the type of tsDat is float32\n",
      "\n",
      "The shape of trLbl is (6042,) and the type of trLbl is <U12\n",
      "The shape of tsLbl is (1511,) and the type of tsLbl is <U12\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import os, sys\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def collect_images_and_labels(path_to_images):\n",
    "    # in seguito, usare https://keras.io/api/preprocessing/image/\n",
    "    \"\"\"\n",
    "        :param path_to_images should be the root folder, in which there is a folder for each label, and the folder's name is\n",
    "        the label itself\n",
    "        :return: a list with images and a list with labels\n",
    "        \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for img_path in list(paths.list_images(path_to_images)):\n",
    "        # extract the class label from the filename\n",
    "        label = img_path.split(os.path.sep)[-2]\n",
    "\n",
    "        # load the input image as (224x224) and preprocess it\n",
    "        image = load_img(img_path, target_size=(128, 128))\n",
    "        image = img_to_array(image)\n",
    "        #image = preprocess_input(image)\n",
    "\n",
    "        # update the data and labels lists, respectively\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def preprocess_labels(labels):\n",
    "    \"\"\"\n",
    "    :param labels: list of string\n",
    "    :return: np array of 0/1\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "def tts_split(data, labels):\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.20, stratify=labels,\n",
    "                                                          random_state=42)\n",
    "    (x_train, x_test, y_train, y_test) = (np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "PATH_TO_IMAGE = \"../data\"\n",
    "MODELS_PATH = \"../models\"\n",
    "\n",
    "# Step 1\n",
    "\n",
    "data, labels = collect_images_and_labels(PATH_TO_IMAGE)\n",
    "#labels = preprocess_labels(labels)\n",
    "trDat, tsDat, trLbl, tsLbl = tts_split(data, labels)\n",
    "\n",
    "\n",
    "# Step 2\n",
    "print(\"The shape of trDat is\", trDat.shape, \"and the type of trDat is\", trDat.dtype)\n",
    "print(\"The shape of tsDat is\", tsDat.shape, \"and the type of tsDat is\", tsDat.dtype)\n",
    "print(\"\")\n",
    "print(\"The shape of trLbl is\", trLbl.shape, \"and the type of trLbl is\", trLbl.dtype)\n",
    "print(\"The shape of tsLbl is\", tsLbl.shape, \"and the type of tsLbl is\", tsLbl.dtype)\n",
    "\n",
    "\n",
    "# Step 3\n",
    "trDat           = trDat.astype('float32')/255\n",
    "tsDat           = tsDat.astype('float32')/255\n",
    "\n",
    "# Step 4\n",
    "imgrows         = trDat.shape[1]\n",
    "imgclms         = trDat.shape[2]\n",
    "channel         = trDat.shape[3]\n",
    "\n",
    "# Step 5\n",
    "trLbl           = preprocess_labels(trLbl)\n",
    "tsLbl           = preprocess_labels(tsLbl)\n",
    "\n",
    "# Step 6\n",
    "num_classes     = tsLbl.shape[1]           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Define the wBNRg model (to be completed)**\n",
    "___\n",
    "* Step 1: Setup the optimizer to be used for training\n",
    "* Step 2: Set a name for the coming model (required for saving)\n",
    "* Step 3: Define the convolutional neural network model (to be completed)\n",
    "* Step 4: Create models for training and testing\n",
    "* Step 5: Display the summary of the model of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 224)     33152     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 224)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 224)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 128)     1405056   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 64)        401472    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,051,138\n",
      "Trainable params: 5,051,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "optmz       = optimizers.RMSprop(lr=0.0001)\n",
    "# Step 2\n",
    "modelname   = 'DetecitveMask'                                                           \n",
    "\n",
    "# Step 3                                                                               \n",
    "def createModel():\n",
    "    \n",
    "    ipt = Input(shape=(imgrows, imgclms, channel))\n",
    "    x = Conv2D(128,(3,3),padding='same')(ipt)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(32,(3,3),padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=ipt, outputs=x)\n",
    "#    if (tf.test.is_built_with_cuda()):\n",
    "#        from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "#        model = multi_gpu_model(model, gpus=0)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 4                                                                                \n",
    "model       = createModel() # This is meant for training\n",
    "modelGo     = createModel() # This is used for final testing\n",
    "\n",
    "# Step 5\n",
    "model.summary()                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Create the checkpoints to be applied during training**\n",
    "---\n",
    "* Step 1: Create a checkpoint to save the model from an epoch when validation accuracy is the highest\n",
    "* Step 2: Create a checkpoint to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
    "* Step 3: Put the two checkpoint objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks created:\n",
      "<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x00000284F9BDCA48>\n",
      "<tensorflow.python.keras.callbacks.CSVLogger object at 0x00000284F9BDCD08>\n",
      "\n",
      "Path to model: ../models/DetecitveMask.hdf5\n",
      "Path to log:   ../models/DetecitveMask.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "folderpath      = MODELS_PATH + '/'\n",
    "filepath        = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "# Step 2\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')\n",
    "\n",
    "# Step 3\n",
    "callbacks_list  = [checkpoint,csv_logger]                                       \n",
    "\n",
    "print(\"Callbacks created:\")\n",
    "print(callbacks_list[0])\n",
    "print(callbacks_list[1])\n",
    "print('')\n",
    "print(\"Path to model:\", filepath)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Train the deep learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 39/189 [=====>........................] - ETA: 1:11:07 - loss: 7.6164 - accuracy: 0.5160"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(trDat,                    # Training data\n",
    "          trLbl,                            # Training label\n",
    "          validation_data=(tsDat, tsLbl),   # Validation data and label\n",
    "          epochs=10,                       # The amount of epochs to be trained\n",
    "          batch_size=32,                   \n",
    "          shuffle=True,                     # To shuffle the training data\n",
    "          callbacks=callbacks_list)         # Callbacks to execute the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c74ed16f167f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'device_lib' is not defined"
     ]
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
