{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MGncGXEsxuM"
   },
   "source": [
    "## **1. Import the necessary libraries** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1633844825164,
     "user": {
      "displayName": "Qi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17326875720265315886"
     },
     "user_tz": -480
    },
    "id": "p99RaBLBsxuP",
    "outputId": "6114fb93-52c4-4b57-9a18-a61fbb439b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  2.3.0\n",
      "numpy:       1.20.3\n",
      "matplotlib:  3.4.2\n",
      "sklearn:     0.24.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSeUaZU8sxuR"
   },
   "source": [
    "## **2.Create a function to plot image without axis** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "error",
     "timestamp": 1633844297324,
     "user": {
      "displayName": "Qi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17326875720265315886"
     },
     "user_tz": -480
    },
    "id": "7CkkJVY9sxuR",
    "outputId": "e7d58207-27aa-4f88-cf61-eec4b0cb2a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function implt at 0x000001FF23DE7DC8>\n"
     ]
    }
   ],
   "source": [
    "def implt(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(implt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3IzcS3psxuS"
   },
   "source": [
    "## **3. Set matplotlib to have seaborn plot style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "error",
     "timestamp": 1633844207778,
     "user": {
      "displayName": "Qi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17326875720265315886"
     },
     "user_tz": -480
    },
    "id": "lM70XFbisxuS",
    "outputId": "138b5e1a-2d90-4e7c-9660-cfcdd6f67d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib setup completes.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEr_3AgusxuT"
   },
   "source": [
    "## **4. Prepare data for training and testing**\n",
    "---\n",
    "* Step 1: Load the images\n",
    "* Step 2: Check the shape and type of the data\n",
    "* Step 3: Convert the data into float32 and rescale the values from the range of 0\\~255 into 0\\~1\n",
    "* Step 4: Retrieve the row size and the column size of each image\n",
    "* Step 5: Perform one-hot enconding on the labels\n",
    "* Step 6: Retrieve the number of classes in this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "error",
     "timestamp": 1633844436310,
     "user": {
      "displayName": "Qi",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17326875720265315886"
     },
     "user_tz": -480
    },
    "id": "RnAQBJdnsxuT",
    "outputId": "7d9ebcb0-ef54-445c-da71-077e20a63e63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\detective_mask\\lib\\site-packages\\PIL\\Image.py:974: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trDat is (6042, 128, 128, 3) and the type of trDat is float32\n",
      "The shape of tsDat is (1511, 128, 128, 3) and the type of tsDat is float32\n",
      "\n",
      "The shape of trLbl is (6042,) and the type of trLbl is <U12\n",
      "The shape of tsLbl is (1511,) and the type of tsLbl is <U12\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import os, sys\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def collect_images_and_labels(path_to_images):\n",
    "    # in seguito, usare https://keras.io/api/preprocessing/image/\n",
    "    \"\"\"\n",
    "        :param path_to_images should be the root folder, in which there is a folder for each label, and the folder's name is\n",
    "        the label itself\n",
    "        :return: a list with images and a list with labels\n",
    "        \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for img_path in list(paths.list_images(path_to_images)):\n",
    "        # extract the class label from the filename\n",
    "        label = img_path.split(os.path.sep)[-2]\n",
    "\n",
    "        # load the input image as (128x128) and preprocess it\n",
    "        image = load_img(img_path, target_size=(128, 128))\n",
    "        image = img_to_array(image)\n",
    "        #image = preprocess_input(image)\n",
    "\n",
    "        # update the data and labels lists, respectively\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def preprocess_labels(labels):\n",
    "    \"\"\"\n",
    "    :param labels: list of string\n",
    "    :return: np array of 0/1\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "def tts_split(data, labels):\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)\n",
    "    (x_train, x_test, y_train, y_test) = (np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "PATH_TO_IMAGE = \"../data\"\n",
    "MODELS_PATH = \"../models\"\n",
    "\n",
    "# Step 1\n",
    "\n",
    "data, labels = collect_images_and_labels(PATH_TO_IMAGE)\n",
    "#labels = preprocess_labels(labels)\n",
    "trDat, tsDat, trLbl, tsLbl = tts_split(data, labels)\n",
    "# x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2\n",
    "print(\"The shape of trDat is\", trDat.shape, \"and the type of trDat is\", trDat.dtype)\n",
    "print(\"The shape of tsDat is\", tsDat.shape, \"and the type of tsDat is\", tsDat.dtype)\n",
    "print(\"\")\n",
    "print(\"The shape of trLbl is\", trLbl.shape, \"and the type of trLbl is\", trLbl.dtype)\n",
    "print(\"The shape of tsLbl is\", tsLbl.shape, \"and the type of tsLbl is\", tsLbl.dtype)\n",
    "\n",
    "\n",
    "# Step 3\n",
    "trDat           = trDat.astype('float32')/255\n",
    "tsDat           = tsDat.astype('float32')/255\n",
    "\n",
    "# Step 4\n",
    "imgrows         = trDat.shape[1]\n",
    "imgclms         = trDat.shape[2]\n",
    "channel         = trDat.shape[3]\n",
    "\n",
    "# Step 5\n",
    "trLbl           = preprocess_labels(trLbl)\n",
    "tsLbl           = preprocess_labels(tsLbl)\n",
    "\n",
    "# Step 6\n",
    "num_classes     = tsLbl.shape[1]           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnV9XC7lsxuU"
   },
   "source": [
    "## *KNN No Hyperparameter Tuning*\n",
    "___\n",
    "\n",
    "\n",
    "Build and train KNN model with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r8p7L1wasxuV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA # Dimensionality Reduction\n",
    "\n",
    "\n",
    "trDat = trDat.reshape(6042, 128*128*3)\n",
    "tsDat = tsDat.reshape(1511, 128*128*3)\n",
    "\n",
    "# Initialize KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Use training data to fit KNN model\n",
    "knn.fit(trDat, trLbl)\n",
    "                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6YSZ1rFlsxuV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make prediction on entire test data\n",
    "predictions_set1 = knn.predict(tsDat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SPqVUOPNsxuW"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save Predictions in a pickle\n",
    "pickle_out = open(\"predictions_knn.pickle\", \"wb\")\n",
    "pickle.dump(predictions_set1, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9DL-uB4sxuW"
   },
   "source": [
    "## **Performance Metrics for No Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2pHEYxX-sxuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Precision: 0.815\n",
      "KNN Recall: 0.815\n",
      "KNN F1 Score: 0.815\n",
      "\n",
      "No Hyperparameter Tuning Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79       745\n",
      "           1       0.76      0.92      0.84       766\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1511\n",
      "   macro avg       0.83      0.81      0.81      1511\n",
      "weighted avg       0.83      0.82      0.81      1511\n",
      " samples avg       0.82      0.82      0.82      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Precision, Recall, F1 Score & Classification Report, No Hyperparameter Tuning\n",
    "print('KNN Precision: %.3f' % precision_score(tsLbl, predictions_set1, average='micro'))\n",
    "print('KNN Recall: %.3f' % recall_score(tsLbl, predictions_set1, average='micro'))\n",
    "print('KNN F1 Score: %.3f' % f1_score(tsLbl, predictions_set1, average='micro'))\n",
    "print(\"\\nNo Hyperparameter Tuning Classification Report\\n\", classification_report(tsLbl, predictions_set1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUZqOI4GsxuX"
   },
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6042, 189)\n",
      "(6042, 49152)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with Principal Component Analysis (PCA)\n",
    "pca = PCA(0.90) # Preserve 90% of the variance\n",
    "\n",
    "X_transformed = pca.fit_transform(trDat) # Fit the pca transform with X_train\n",
    "X_test_transformed = pca.transform(tsDat) # Apply transform to X_test\n",
    "\n",
    "# Training set shape after Principal Component Analysis form\n",
    "print(X_transformed.shape)\n",
    "\n",
    "# Original Training Set Shape\n",
    "# Notice we lose 3,943 features using PCA, while preserving 90% variance\n",
    "print(trDat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize KNN model for PCA instance\n",
    "knn_pca = KNeighborsClassifier()\n",
    "\n",
    "# Use training data to fit KNN model with transformed X_train\n",
    "knn_pca.fit(X_transformed, trLbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train PCA: 0.8391793514228988\n",
      "KNN Recall: 0.839\n",
      "KNN F1 Score: 0.839\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make prediction on entire test data\n",
    "predictions_set_pca = knn_pca.predict(X_test_transformed)\n",
    "print(\"Accuracy Train PCA:\", accuracy_score(tsLbl, predictions_set_pca))\n",
    "print('KNN Recall: %.3f' % recall_score(tsLbl, predictions_set_pca, average='micro'))\n",
    "print('KNN F1 Score: %.3f' % f1_score(tsLbl, predictions_set_pca, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New KNN instance model\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "# Dictionary of parameter values we are testing performance for\n",
    "param_grid = {'n_neighbors': [5, 7, 9, 11], 'p': [2, 4, 6, 8, 10, 20, 50], 'metric': ['euclidean', 'manhattan', 'minkowski']}\n",
    "\n",
    "# Test all parameter combinations in param_grid\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, scoring='f1_micro', cv=5, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit model to data\n",
    "knn_gscv.fit(trDat, trLbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GridSearchCV's top performing parameters and score\n",
    "\n",
    "# Best Params: n_neighbors=5, distance=manhattan, p=2\n",
    "best_params_ = knn_gscv.best_params_\n",
    "\n",
    "# Best Score 82.7%\n",
    "knn_gscv.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'weights': 'distance', 'n_neighbors': 2, 'metric': 'manhattan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 1.000\n",
      "Accuracy Test: 0.809\n",
      "KNN Recall: 0.809\n",
      "KNN F1 Score: 0.809\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       745\n",
      "           1       0.78      0.86      0.82       766\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1511\n",
      "   macro avg       0.81      0.81      0.81      1511\n",
      "weighted avg       0.81      0.81      0.81      1511\n",
      " samples avg       0.81      0.81      0.81      1511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new a knn model with best params\n",
    "b_knn = KNeighborsClassifier(**best_params)\n",
    "\n",
    "#fit model to data\n",
    "b_knn.fit(trDat, trLbl)\n",
    "\n",
    "# make prediction on entire train data\n",
    "train_pred = b_knn.predict(trDat)\n",
    "\n",
    "# make prediction on entire test data\n",
    "y_pred = b_knn.predict(tsDat)\n",
    "\n",
    "print('Accuracy Train: %.3f' % accuracy_score(trLbl, train_pred))\n",
    "print('Accuracy Test: %.3f' % accuracy_score(tsLbl, y_pred))\n",
    "print('KNN Recall: %.3f' % recall_score(tsLbl, y_pred, average='micro'))\n",
    "print('KNN F1 Score: %.3f' % f1_score(tsLbl, y_pred, average='micro'))\n",
    "print(\"\\nClassification Report\\n\", classification_report(tsLbl, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6042, 189)\n",
      "(6042, 49152)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with Principal Component Analysis (PCA)\n",
    "pca = PCA(0.90) # Preserve 90% of the variance\n",
    "\n",
    "X_transformed = pca.fit_transform(trDat) # Fit the pca transform with X_train\n",
    "X_test_transformed = pca.transform(tsDat) # Apply transform to X_test\n",
    "\n",
    "# Training set shape after Principal Component Analysis form\n",
    "print(X_transformed.shape)\n",
    "\n",
    "# Original Training Set Shape\n",
    "# Notice we lose 3,943 features using PCA, while preserving 90% variance\n",
    "print(trDat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(metric='manhattan', n_neighbors=2, weights='distance')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize KNN model for PCA instance\n",
    "knn_pca2 = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Use training data to fit KNN model with transformed X_train\n",
    "knn_pca2.fit(X_transformed, trLbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train PCA: 0.7875579086697552\n",
      "KNN Recall: 0.788\n",
      "KNN F1 Score: 0.788\n",
      "Wall time: 2.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make prediction on entire test data\n",
    "predictions_set_pca = knn_pca2.predict(X_test_transformed)\n",
    "print(\"Accuracy Train PCA:\", accuracy_score(tsLbl, predictions_set_pca))\n",
    "print('KNN Recall: %.3f' % recall_score(tsLbl, predictions_set_pca, average='micro'))\n",
    "print('KNN F1 Score: %.3f' % f1_score(tsLbl, predictions_set_pca, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model_v1-Copy1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
