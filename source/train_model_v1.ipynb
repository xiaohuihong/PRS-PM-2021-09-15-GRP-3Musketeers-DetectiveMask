{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import the necessary libraries** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  2.3.0\n",
      "numpy:       1.18.5\n",
      "matplotlib:  3.4.2\n",
      "sklearn:     0.24.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.Create a function to plot image without axis** ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function implt at 0x0000024A79E90678>\n"
     ]
    }
   ],
   "source": [
    "def implt(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(implt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Set matplotlib to have seaborn plot style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib setup completes.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Prepare data for training and testing**\n",
    "---\n",
    "* Step 1: Load the images\n",
    "* Step 2: Check the shape and type of the data\n",
    "* Step 3: Convert the data into float32 and rescale the values from the range of 0\\~255 into 0\\~1\n",
    "* Step 4: Retrieve the row size and the column size of each image\n",
    "* Step 5: Perform one-hot enconding on the labels\n",
    "* Step 6: Retrieve the number of classes in this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HONG0\\.conda\\envs\\detective_mask\\lib\\site-packages\\PIL\\Image.py:974: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trDat is (6042, 128, 128, 3) and the type of trDat is float32\n",
      "The shape of tsDat is (1511, 128, 128, 3) and the type of tsDat is float32\n",
      "\n",
      "The shape of trLbl is (6042,) and the type of trLbl is <U12\n",
      "The shape of tsLbl is (1511,) and the type of tsLbl is <U12\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import os, sys\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def collect_images_and_labels(path_to_images):\n",
    "    # in seguito, usare https://keras.io/api/preprocessing/image/\n",
    "    \"\"\"\n",
    "        :param path_to_images should be the root folder, in which there is a folder for each label, and the folder's name is\n",
    "        the label itself\n",
    "        :return: a list with images and a list with labels\n",
    "        \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for img_path in list(paths.list_images(path_to_images)):\n",
    "        # extract the class label from the filename\n",
    "        label = img_path.split(os.path.sep)[-2]\n",
    "\n",
    "        # load the input image as (224x224) and preprocess it\n",
    "        image = load_img(img_path, target_size=(128, 128))\n",
    "        image = img_to_array(image)\n",
    "        #image = preprocess_input(image)\n",
    "\n",
    "        # update the data and labels lists, respectively\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def preprocess_labels(labels):\n",
    "    \"\"\"\n",
    "    :param labels: list of string\n",
    "    :return: np array of 0/1\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    return labels\n",
    "\n",
    "def tts_split(data, labels):\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.20, stratify=labels,\n",
    "                                                          random_state=42)\n",
    "    (x_train, x_test, y_train, y_test) = (np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "PATH_TO_IMAGE = \"../data\"\n",
    "MODELS_PATH = \"../models\"\n",
    "\n",
    "# Step 1\n",
    "\n",
    "data, labels = collect_images_and_labels(PATH_TO_IMAGE)\n",
    "#labels = preprocess_labels(labels)\n",
    "trDat, tsDat, trLbl, tsLbl = tts_split(data, labels)\n",
    "\n",
    "\n",
    "# Step 2\n",
    "print(\"The shape of trDat is\", trDat.shape, \"and the type of trDat is\", trDat.dtype)\n",
    "print(\"The shape of tsDat is\", tsDat.shape, \"and the type of tsDat is\", tsDat.dtype)\n",
    "print(\"\")\n",
    "print(\"The shape of trLbl is\", trLbl.shape, \"and the type of trLbl is\", trLbl.dtype)\n",
    "print(\"The shape of tsLbl is\", tsLbl.shape, \"and the type of tsLbl is\", tsLbl.dtype)\n",
    "\n",
    "\n",
    "# Step 3\n",
    "trDat           = trDat.astype('float32')/255\n",
    "tsDat           = tsDat.astype('float32')/255\n",
    "\n",
    "# Step 4\n",
    "imgrows         = trDat.shape[1]\n",
    "imgclms         = trDat.shape[2]\n",
    "channel         = trDat.shape[3]\n",
    "\n",
    "# Step 5\n",
    "trLbl           = preprocess_labels(trLbl)\n",
    "tsLbl           = preprocess_labels(tsLbl)\n",
    "\n",
    "# Step 6\n",
    "num_classes     = tsLbl.shape[1]           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Define the wBNRg model (to be completed)**\n",
    "___\n",
    "* Step 1: Setup the optimizer to be used for training\n",
    "* Step 2: Set a name for the coming model (required for saving)\n",
    "* Step 3: Define the convolutional neural network model (to be completed)\n",
    "* Step 4: Create models for training and testing\n",
    "* Step 5: Display the summary of the model of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 128, 128)     3584      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                524352    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 620,322\n",
      "Trainable params: 620,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "optmz       = optimizers.RMSprop(lr=0.0001)\n",
    "# Step 2\n",
    "modelname   = 'DetecitveMask'                                                           \n",
    "\n",
    "# Step 3                                                                               \n",
    "def createModel():\n",
    "    \n",
    "    ipt = Input(shape=(imgrows, imgclms, channel))\n",
    "    x = Conv2D(128,(3,3),padding='same')(ipt)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(64,(3,3),padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Conv2D(32,(3,3),padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=ipt, outputs=x)\n",
    "#    if (tf.test.is_built_with_cuda()):\n",
    "#        from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "#        model = multi_gpu_model(model, gpus=0)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 4                                                                                \n",
    "model       = createModel() # This is meant for training\n",
    "modelGo     = createModel() # This is used for final testing\n",
    "\n",
    "# Step 5\n",
    "model.summary()                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Create the checkpoints to be applied during training**\n",
    "---\n",
    "* Step 1: Create a checkpoint to save the model from an epoch when validation accuracy is the highest\n",
    "* Step 2: Create a checkpoint to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
    "* Step 3: Put the two checkpoint objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks created:\n",
      "<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x0000024A5707C948>\n",
      "<tensorflow.python.keras.callbacks.CSVLogger object at 0x0000024A6352CF08>\n",
      "\n",
      "Path to model: ../models/DetecitveMask.hdf5\n",
      "Path to log:   ../models/DetecitveMask.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "folderpath      = MODELS_PATH + '/'\n",
    "filepath        = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "# Step 2\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')\n",
    "\n",
    "# Step 3\n",
    "callbacks_list  = [checkpoint,csv_logger]                                       \n",
    "\n",
    "print(\"Callbacks created:\")\n",
    "print(callbacks_list[0])\n",
    "print(callbacks_list[1])\n",
    "print('')\n",
    "print(\"Path to model:\", filepath)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Train the deep learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "95/95 [==============================] - 130s 1s/step - loss: 0.5309 - accuracy: 0.7315 - val_loss: 0.3135 - val_accuracy: 0.8709\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - 153s 2s/step - loss: 0.3049 - accuracy: 0.8762 - val_loss: 0.2320 - val_accuracy: 0.9219\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - 168s 2s/step - loss: 0.2401 - accuracy: 0.9057 - val_loss: 0.4426 - val_accuracy: 0.8299\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - 171s 2s/step - loss: 0.1923 - accuracy: 0.9308 - val_loss: 0.2435 - val_accuracy: 0.9001\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.1535 - accuracy: 0.9451 - val_loss: 0.2322 - val_accuracy: 0.9153\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.1293 - accuracy: 0.9553 - val_loss: 0.1420 - val_accuracy: 0.9457\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - 176s 2s/step - loss: 0.1128 - accuracy: 0.9608 - val_loss: 0.1487 - val_accuracy: 0.9563\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - 176s 2s/step - loss: 0.0864 - accuracy: 0.9702 - val_loss: 0.1652 - val_accuracy: 0.9570\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0754 - accuracy: 0.9752 - val_loss: 0.2290 - val_accuracy: 0.9365\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0517 - accuracy: 0.9813 - val_loss: 0.2373 - val_accuracy: 0.9471\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - 173s 2s/step - loss: 0.0512 - accuracy: 0.9841 - val_loss: 0.2031 - val_accuracy: 0.9570\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.0354 - accuracy: 0.9874 - val_loss: 0.2234 - val_accuracy: 0.9557\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - 176s 2s/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.3043 - val_accuracy: 0.9523\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - 173s 2s/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.4527 - val_accuracy: 0.9411\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - 173s 2s/step - loss: 0.0323 - accuracy: 0.9924 - val_loss: 0.3591 - val_accuracy: 0.9477\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.0436 - accuracy: 0.9906 - val_loss: 0.3264 - val_accuracy: 0.9570\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.4749 - val_accuracy: 0.9437\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - 173s 2s/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.4200 - val_accuracy: 0.9510\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.7188 - val_accuracy: 0.9424\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.4852 - val_accuracy: 0.9543\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.0249 - accuracy: 0.9935 - val_loss: 0.6225 - val_accuracy: 0.9285\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0857 - accuracy: 0.9926 - val_loss: 0.3647 - val_accuracy: 0.9523\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.6016 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - 173s 2s/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 0.5329 - val_accuracy: 0.9510\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.5802 - val_accuracy: 0.9550\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - 175s 2s/step - loss: 0.0436 - accuracy: 0.9914 - val_loss: 0.5153 - val_accuracy: 0.9471\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.6741 - val_accuracy: 0.9490\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - 174s 2s/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.6089 - val_accuracy: 0.9497\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - 190s 2s/step - loss: 0.0594 - accuracy: 0.9935 - val_loss: 0.6566 - val_accuracy: 0.9576\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0235 - accuracy: 0.9955 - val_loss: 0.6211 - val_accuracy: 0.9517\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.7623 - val_accuracy: 0.9576\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0184 - accuracy: 0.9960 - val_loss: 0.7039 - val_accuracy: 0.9530\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - 210s 2s/step - loss: 0.0212 - accuracy: 0.9967 - val_loss: 0.7112 - val_accuracy: 0.9530\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - 196s 2s/step - loss: 0.0278 - accuracy: 0.9950 - val_loss: 0.7713 - val_accuracy: 0.9576\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - 198s 2s/step - loss: 0.0410 - accuracy: 0.9924 - val_loss: 1.1769 - val_accuracy: 0.9232\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - 183s 2s/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 0.6453 - val_accuracy: 0.9543\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - 183s 2s/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 0.9061 - val_accuracy: 0.9497\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - 178s 2s/step - loss: 0.0197 - accuracy: 0.9964 - val_loss: 0.7752 - val_accuracy: 0.9557\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - 183s 2s/step - loss: 0.0190 - accuracy: 0.9974 - val_loss: 1.2371 - val_accuracy: 0.9517\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.6703 - val_accuracy: 0.9484\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 1.0022 - val_accuracy: 0.9451\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0185 - accuracy: 0.9978 - val_loss: 0.8029 - val_accuracy: 0.9490\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.7761 - val_accuracy: 0.9543\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.9027 - val_accuracy: 0.9517\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 0.0298 - accuracy: 0.9960 - val_loss: 0.8748 - val_accuracy: 0.9504\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 0.0233 - accuracy: 0.9977 - val_loss: 0.7691 - val_accuracy: 0.9510\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0149 - accuracy: 0.9987 - val_loss: 0.9877 - val_accuracy: 0.9517\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 1.2562 - val_accuracy: 0.9437\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 0.0176 - accuracy: 0.9965 - val_loss: 0.9484 - val_accuracy: 0.9523\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0391 - accuracy: 0.9974 - val_loss: 1.4487 - val_accuracy: 0.9484\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - 197s 2s/step - loss: 0.0208 - accuracy: 0.9970 - val_loss: 0.9277 - val_accuracy: 0.9557\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - 204s 2s/step - loss: 4.1037e-05 - accuracy: 1.0000 - val_loss: 1.3933 - val_accuracy: 0.9557\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - 201s 2s/step - loss: 0.0452 - accuracy: 0.9960 - val_loss: 1.1761 - val_accuracy: 0.9543\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - 189s 2s/step - loss: 0.0233 - accuracy: 0.9978 - val_loss: 1.0615 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 1.0003 - val_accuracy: 0.9530\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 0.8951 - val_accuracy: 0.9530\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0224 - accuracy: 0.9967 - val_loss: 1.0423 - val_accuracy: 0.9477\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 179s 2s/step - loss: 0.0221 - accuracy: 0.9967 - val_loss: 1.2499 - val_accuracy: 0.9517\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0212 - accuracy: 0.9974 - val_loss: 1.0146 - val_accuracy: 0.9391\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - 178s 2s/step - loss: 0.0220 - accuracy: 0.9970 - val_loss: 1.1733 - val_accuracy: 0.9358\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 1.0456 - val_accuracy: 0.9497\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 1.3798 - val_accuracy: 0.9365\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 1.4355 - val_accuracy: 0.9451\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0159 - accuracy: 0.9980 - val_loss: 1.5257 - val_accuracy: 0.9504\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.9260 - val_accuracy: 0.9431\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 0.0284 - accuracy: 0.9969 - val_loss: 1.0913 - val_accuracy: 0.9457\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - 178s 2s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 1.5396 - val_accuracy: 0.9510\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - 179s 2s/step - loss: 1.8269e-04 - accuracy: 1.0000 - val_loss: 1.5931 - val_accuracy: 0.9477\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 0.0169 - accuracy: 0.9988 - val_loss: 1.2728 - val_accuracy: 0.9437\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 1.0752 - val_accuracy: 0.9490\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - 180s 2s/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 1.2187 - val_accuracy: 0.9504\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - 190s 2s/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 1.1604 - val_accuracy: 0.9523\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 1.0864e-04 - accuracy: 1.0000 - val_loss: 1.3646 - val_accuracy: 0.9510\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0193 - accuracy: 0.9987 - val_loss: 1.3162 - val_accuracy: 0.9530\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - 186s 2s/step - loss: 8.6834e-06 - accuracy: 1.0000 - val_loss: 1.5256 - val_accuracy: 0.9510\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 1.6593e-08 - accuracy: 1.0000 - val_loss: 1.5305 - val_accuracy: 0.9530\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - 185s 2s/step - loss: 1.0457e-09 - accuracy: 1.0000 - val_loss: 1.6099 - val_accuracy: 0.9523\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 7.8920e-11 - accuracy: 1.0000 - val_loss: 1.6171 - val_accuracy: 0.9530\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 1.9730e-11 - accuracy: 1.0000 - val_loss: 1.6216 - val_accuracy: 0.9530\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6255 - val_accuracy: 0.9530\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6315 - val_accuracy: 0.9537\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 1.9730e-11 - accuracy: 1.0000 - val_loss: 1.6326 - val_accuracy: 0.9543\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6370 - val_accuracy: 0.9543\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.9543\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6464 - val_accuracy: 0.9530\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - 182s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.9537\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - 183s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6505 - val_accuracy: 0.9530\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - 183s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.9530\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - 183s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6552 - val_accuracy: 0.9530\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6570 - val_accuracy: 0.9530\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - 187s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6594 - val_accuracy: 0.9530\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - 186s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6620 - val_accuracy: 0.9530\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6645 - val_accuracy: 0.9530\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6662 - val_accuracy: 0.9530\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - 181s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6682 - val_accuracy: 0.9530\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.9530\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6720 - val_accuracy: 0.9530\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6735 - val_accuracy: 0.9530\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6758 - val_accuracy: 0.9530\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - 184s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6788 - val_accuracy: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a570824c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(trDat,                    # Training data\n",
    "          trLbl,                            # Training label\n",
    "          validation_data=(tsDat, tsLbl),   # Validation data and label\n",
    "          epochs=100,                       # The amount of epochs to be trained\n",
    "          batch_size=64,                   \n",
    "          shuffle=True,                     # To shuffle the training data\n",
    "          callbacks=callbacks_list)         # Callbacks to execute the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c74ed16f167f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'device_lib' is not defined"
     ]
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print(get_available_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
